{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "576d5ebae30e4237be9cb174f053e563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae0f1e09f9c44ebf81c01bb9d140b662",
              "IPY_MODEL_4465a9fa1d614cb3825cb5e621c81d28",
              "IPY_MODEL_87df4f5cb3bf43479c3176bad8f2b3ed"
            ],
            "layout": "IPY_MODEL_5e7e6051095f44fd8058f56148dbd7b6"
          }
        },
        "ae0f1e09f9c44ebf81c01bb9d140b662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8534ce5821344e3bb643b2ab098e0bcf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ff01945627a34b9eafed9e3429779e90",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "4465a9fa1d614cb3825cb5e621c81d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_417912e7971a4ed9b7ea75d2fa10b363",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d31c3e13964c42fb84aea0febe6a12d5",
            "value": 103
          }
        },
        "87df4f5cb3bf43479c3176bad8f2b3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9867734075bd40acb18e327f71ac4a82",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2023e6a78b0b48f5a08628cd13d23c35",
            "value": "‚Äá103/103‚Äá[00:00&lt;00:00,‚Äá457.36it/s,‚ÄáMaterializing‚Äáparam=pooler.dense.weight]"
          }
        },
        "5e7e6051095f44fd8058f56148dbd7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8534ce5821344e3bb643b2ab098e0bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff01945627a34b9eafed9e3429779e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "417912e7971a4ed9b7ea75d2fa10b363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31c3e13964c42fb84aea0febe6a12d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9867734075bd40acb18e327f71ac4a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2023e6a78b0b48f5a08628cd13d23c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QenprS4h2Szc",
        "outputId": "18c02097-74d7-4e29-951b-87e4865cf7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.16.0)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.0.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.3.7)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (26.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (11.3.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (6.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (8.3.1)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, faiss-cpu, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.9 faiss-cpu-1.13.2 python-pptx-1.0.2\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "\n",
        "!pip install sentence-transformers faiss-cpu openai python-pptx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pptx import Presentation\n",
        "from openai import OpenAI\n"
      ],
      "metadata": {
        "id": "BIeuGhd02Tz5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#upload ppt\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # select L2-Human.pptx\n",
        "pptx_file = list(uploaded.keys())[0]\n",
        "print(\"Uploaded file:\", pptx_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "psssQy_x3L0N",
        "outputId": "545beb4f-f680-4b8b-f9cb-9a92c17aca21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5fed860b-e5e5-4a84-b27c-ad85a6232898\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5fed860b-e5e5-4a84-b27c-ad85a6232898\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving L2 - Human (1).pptx to L2 - Human (1).pptx\n",
            "Uploaded file: L2 - Human (1).pptx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from PPT file\n",
        "\n",
        "def extract_text_from_ppt(ppt_path):\n",
        "    presentation = Presentation(ppt_path)\n",
        "    text = \"\"\n",
        "\n",
        "    for slide in presentation.slides:\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\"):\n",
        "                text += shape.text + \"\\n\"\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Provide your PPT file path\n",
        "ppt_path = \"L2 - Human (1).pptx\"   # üî• CHANGE THIS\n",
        "\n",
        "# Extract text\n",
        "text = extract_text_from_ppt(ppt_path)\n",
        "\n",
        "print(\"Text extraction complete.\")\n",
        "print(text[:500])  # Preview first 500 characters\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7W-gZZE4NpV",
        "outputId": "0fe45471-3670-4abf-e60e-8ef91d6f8a48"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extraction complete.\n",
            "The Human\n",
            "\n",
            "Ref: Human Computer Interaction- Alan Dix, Janet Finlay, Gregory D Abowd, Russell Beale\n",
            "Human, one of the first component in HCI\n",
            "\n",
            "Human, the user, is after all the one whom computer systems are designed to assist.\n",
            "\n",
            "The requirement of user is therefore the priority.\n",
            "\n",
            "\n",
            "Introduction\n",
            "Human psychology (cognitive psychology)\n",
            "Understand the capabilities and limitations\n",
            "Find the things  that are difficult and impossible\n",
            "How human perceive the world around them, how they store and process info\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split text into smaller chunks\n",
        "\n",
        "def chunk_text(text, chunk_size=500, overlap=50):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunks.append(text[start:end])\n",
        "        start = end - overlap\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Create chunks\n",
        "chunks = chunk_text(text, chunk_size=500)\n",
        "\n",
        "print(\"Total chunks created:\", len(chunks))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cki-M2_D4SXv",
        "outputId": "e83ebd7e-05f8-4c52-8717-e80a7f61ce28"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks created: 124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load embedding model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Convert chunks into embeddings\n",
        "chunk_embeddings = embedding_model.encode(chunks)\n",
        "\n",
        "print(\"Embeddings created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "576d5ebae30e4237be9cb174f053e563",
            "ae0f1e09f9c44ebf81c01bb9d140b662",
            "4465a9fa1d614cb3825cb5e621c81d28",
            "87df4f5cb3bf43479c3176bad8f2b3ed",
            "5e7e6051095f44fd8058f56148dbd7b6",
            "8534ce5821344e3bb643b2ab098e0bcf",
            "ff01945627a34b9eafed9e3429779e90",
            "417912e7971a4ed9b7ea75d2fa10b363",
            "d31c3e13964c42fb84aea0febe6a12d5",
            "9867734075bd40acb18e327f71ac4a82",
            "2023e6a78b0b48f5a08628cd13d23c35"
          ]
        },
        "id": "lklVj1Fn4XCP",
        "outputId": "4dd62e39-8959-4f28-9e25-323e8d86024c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "576d5ebae30e4237be9cb174f053e563"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embedding dimension\n",
        "dimension = chunk_embeddings.shape[1]\n",
        "\n",
        "# Create FAISS index\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Add embeddings to index\n",
        "index.add(np.array(chunk_embeddings))\n",
        "\n",
        "print(\"FAISS index created and embeddings stored.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKD1BmsP4ZbQ",
        "outputId": "4f8cd751-7bd8-4c5c-898f-3607bbf1a047"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index created and embeddings stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask user question\n",
        "query = input(\"Enter your question: \")\n",
        "\n",
        "# Convert query into embedding\n",
        "query_embedding = embedding_model.encode([query])\n",
        "\n",
        "# Search top 3 similar chunks\n",
        "k = 3\n",
        "distances, indices = index.search(np.array(query_embedding), k)\n",
        "\n",
        "# Retrieve actual text chunks\n",
        "retrieved_chunks = [chunks[i] for i in indices[0]]\n",
        "\n",
        "# Combine retrieved chunks into context\n",
        "context = \"\\n\\n\".join(retrieved_chunks)\n",
        "\n",
        "print(\"\\nRetrieved Context:\\n\")\n",
        "print(context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWkF2a1-4uxc",
        "outputId": "531eb5b9-26c3-4f28-dfa8-a7ec10cc15fc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question: Why is brightness important in HCI design?\n",
            "\n",
            "Retrieved Context:\n",
            "\n",
            "reen at low brightness looks darker because it emits less light.\n",
            "The brain uses luminance information to judge how bright the screen appears.\n",
            "\n",
            "Processing and Interpretation of stimulus\n",
            "Importance of brightness in HCI\n",
            "In HCI, designers must consider brightness so that interfaces are:\n",
            "Easy to see\n",
            "Comfortable for the eyes\n",
            "Usable in different lighting conditions (daylight, night, indoors)\n",
            "In HCI, understanding how users perceive brightness helps designers create interfaces that are clear, readable, \n",
            "\n",
            "gners create interfaces that are clear, readable, and comfortable to use.\n",
            "Practical HCI examples\n",
            "Adjustable brightness: Users can increase or decrease screen brightness based on their surroundings.\n",
            "Dark mode: Uses darker backgrounds with lighter text to reduce eye strain, especially at night.\n",
            "Good color contrast: Clear contrast between text and background improves readability.\n",
            "\n",
            "Processing and Interpretation of stimulus\n",
            "A third factor that we need to consider is perception of color\n",
            "Color percepti\n",
            "\n",
            "umans can perceive around 7 million different colors.\n",
            "\n",
            "Processing and Interpretation of stimulus\n",
            "Importance of color perception in HCI\n",
            "In HCI, understanding color perception helps designers to:\n",
            "Make buttons and text easy to distinguish\n",
            "Improve readability and clarity\n",
            "Create visually pleasing interfaces\n",
            "Design accessible systems for users with color vision deficiencies\n",
            "\n",
            "HCI Examples\n",
            "Using red for errors and green for success messages\n",
            "Maintaining good contrast between text and background\n",
            "Avoiding \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW7RckXF7SHT",
        "outputId": "4e99a39a-2c4f-4633-c930-05197d6a02e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"   # üî• apni key yaha daalo\n",
        "\n",
        "client = Groq()\n"
      ],
      "metadata": {
        "id": "S0anw5PI9-eJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",   # ‚úÖ Correct model\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hROFYbWP-iza",
        "outputId": "77ab6cf6-a66a-4a57-8a4d-b1df9d9184f0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Information not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Retrieved Chunks:\\n\")\n",
        "for i, chunk in enumerate(retrieved_chunks):\n",
        "    print(f\"\\n--- Chunk {i+1} ---\\n\")\n",
        "    print(chunk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nW5MiJ--yxF",
        "outputId": "1fbd86fe-aea4-4e35-9fd3-f2a1061c8428"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved Chunks:\n",
            "\n",
            "\n",
            "--- Chunk 1 ---\n",
            "\n",
            "reen at low brightness looks darker because it emits less light.\n",
            "The brain uses luminance information to judge how bright the screen appears.\n",
            "\n",
            "Processing and Interpretation of stimulus\n",
            "Importance of brightness in HCI\n",
            "In HCI, designers must consider brightness so that interfaces are:\n",
            "Easy to see\n",
            "Comfortable for the eyes\n",
            "Usable in different lighting conditions (daylight, night, indoors)\n",
            "In HCI, understanding how users perceive brightness helps designers create interfaces that are clear, readable, \n",
            "\n",
            "--- Chunk 2 ---\n",
            "\n",
            "gners create interfaces that are clear, readable, and comfortable to use.\n",
            "Practical HCI examples\n",
            "Adjustable brightness: Users can increase or decrease screen brightness based on their surroundings.\n",
            "Dark mode: Uses darker backgrounds with lighter text to reduce eye strain, especially at night.\n",
            "Good color contrast: Clear contrast between text and background improves readability.\n",
            "\n",
            "Processing and Interpretation of stimulus\n",
            "A third factor that we need to consider is perception of color\n",
            "Color percepti\n",
            "\n",
            "--- Chunk 3 ---\n",
            "\n",
            "umans can perceive around 7 million different colors.\n",
            "\n",
            "Processing and Interpretation of stimulus\n",
            "Importance of color perception in HCI\n",
            "In HCI, understanding color perception helps designers to:\n",
            "Make buttons and text easy to distinguish\n",
            "Improve readability and clarity\n",
            "Create visually pleasing interfaces\n",
            "Design accessible systems for users with color vision deficiencies\n",
            "\n",
            "HCI Examples\n",
            "Using red for errors and green for success messages\n",
            "Maintaining good contrast between text and background\n",
            "Avoiding \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0vGULTmB_Rl0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}